{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ea65a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:\t\t3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]\n",
      "Numpy:\t\t1.24.3\n",
      "Tensorflow:\t2.10.0\n",
      "Keras:\t\t2.10.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import sys\n",
    "print(f\"Python:\\t\\t{sys.version}\")\n",
    "import numpy as np\n",
    "print(f\"Numpy:\\t\\t{np.__version__}\")\n",
    "import tensorflow as tf\n",
    "print(f\"Tensorflow:\\t{tf.__version__}\")\n",
    "import keras\n",
    "print(f\"Keras:\\t\\t{keras.__version__}\")\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c8090a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Options\n",
    "\"\"\"\n",
    "model_name = \"DemooNet_8c_3d_60e_32b\"\n",
    "\n",
    "image_width = 128\n",
    "image_height = 128\n",
    "channels_dim = 3\n",
    "classes_dim = 6\n",
    "batch_size = 32\n",
    "\n",
    "validation_split = 0.2\n",
    "base_learning_rate = 0.001\n",
    "epochs_total = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6565d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pathing\n",
    "\"\"\"\n",
    "SPECTROGRAMS_DIR = \"../data/spectrograms/combined\"\n",
    "TF_MODELS_DIR = \"../data/models_tf\"\n",
    "TFLITE_MODELS_DIR = \"../data/models_tflite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccade3ff-fb9d-417f-988c-dbc465d1780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configure GPU\n",
    "\"\"\"\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "    print(f\"{len(gpus)} physical GPUs\\n{len(logical_gpus)} logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d88358-9dfc-4431-ae5c-d2a4fa45b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions\n",
    "\"\"\"\n",
    "def resize_or_crop(image, label, target_height, target_width):\n",
    "    shape = tf.shape(image)\n",
    "    height, width = shape[0], shape[1]\n",
    "\n",
    "    def crop():\n",
    "        offset_height = (height - target_height) // 2\n",
    "        offset_width = (width - target_width) // 2\n",
    "        return tf.image.crop_to_bounding_box(image, offset_height, offset_width, target_height, target_width)\n",
    "\n",
    "    def resize():\n",
    "        return tf.image.resize(image, [target_height, target_width])\n",
    "\n",
    "    image = tf.cond(\n",
    "        tf.logical_and(height >= target_height, width >= target_width),\n",
    "        true_fn=crop,\n",
    "        false_fn=resize\n",
    "    )\n",
    "    return image, label\n",
    "\n",
    "def one_hot_encode(image, label):\n",
    "    label = tf.one_hot(label, depth=classes_dim)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a074281-97c6-406d-8ab2-47a660ae0468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41186 files belonging to 6 classes.\n",
      "Using 32949 files for training.\n",
      "Found 41186 files belonging to 6 classes.\n",
      "Using 8237 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load data\n",
    "\"\"\"\n",
    "train = tf.keras.utils.image_dataset_from_directory(\n",
    "    SPECTROGRAMS_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    image_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "valid = tf.keras.utils.image_dataset_from_directory(\n",
    "    SPECTROGRAMS_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    image_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "train = train.map(one_hot_encode)\n",
    "valid = valid.map(one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11690a1a-5e14-401d-bed7-c06815a96849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " resizing (Resizing)         (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 16)      448       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 74)        42698     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 74)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 128)       85376     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                524352    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 839,712\n",
      "Trainable params: 839,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train custom model\n",
    "\"\"\"\n",
    "\n",
    "model_input = keras.Input(shape=(image_height, image_width, 3))\n",
    "x = model_input\n",
    "x = layers.Resizing(image_height, image_width)(x)\n",
    "x = layers.Rescaling(1.0 / 255)(x)\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "x = layers.Conv2D(74, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "model_output = layers.Dense(classes_dim, activation=\"softmax\")(x)\n",
    "custom_model = keras.Model(inputs=model_input, outputs=model_output)\n",
    "custom_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c7da0c-859d-4dc9-81b4-8b8a0743431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1030/1030 [==============================] - 42s 30ms/step - loss: 1.6380 - accuracy: 0.2979 - val_loss: 1.4072 - val_accuracy: 0.4333\n",
      "Epoch 2/60\n",
      "1030/1030 [==============================] - 48s 47ms/step - loss: 1.3496 - accuracy: 0.4541 - val_loss: 1.1549 - val_accuracy: 0.5521\n",
      "Epoch 3/60\n",
      "1030/1030 [==============================] - 44s 42ms/step - loss: 1.1896 - accuracy: 0.5293 - val_loss: 1.0595 - val_accuracy: 0.5871\n",
      "Epoch 4/60\n",
      "1030/1030 [==============================] - 48s 46ms/step - loss: 1.0903 - accuracy: 0.5734 - val_loss: 1.0133 - val_accuracy: 0.6143\n",
      "Epoch 5/60\n",
      "1030/1030 [==============================] - 43s 42ms/step - loss: 1.0075 - accuracy: 0.6053 - val_loss: 0.8907 - val_accuracy: 0.6578\n",
      "Epoch 6/60\n",
      "1030/1030 [==============================] - 45s 44ms/step - loss: 0.9346 - accuracy: 0.6380 - val_loss: 0.8731 - val_accuracy: 0.6725\n",
      "Epoch 7/60\n",
      "1030/1030 [==============================] - 50s 49ms/step - loss: 0.8624 - accuracy: 0.6699 - val_loss: 0.8041 - val_accuracy: 0.6959\n",
      "Epoch 8/60\n",
      "1030/1030 [==============================] - ETA: 0s - loss: 0.7884 - accuracy: 0.6984"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train model\n",
    "\"\"\"\n",
    "history_custom = custom_model.fit(train, validation_data=valid, epochs=epochs_total)\n",
    "\n",
    "plt.plot(history_custom.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(history_custom.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c0228-62c6-4005-b086-a9ed5c07d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save model\n",
    "\"\"\"\n",
    "custom_model.save(f\"{TF_MODELS_DIR}/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb6b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert SavedModel (TensorFlow) to .tflite\n",
    "\"\"\"\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(f\"{TF_MODELS_DIR}/{model_name}\")\n",
    "converter.experimental_new_converter = True\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "converter.allow_custom_ops = False\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(f\"{TFLITE_MODELS_DIR}/{model_name}.tflite\", \"wb\") as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
